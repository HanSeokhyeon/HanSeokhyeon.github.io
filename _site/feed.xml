<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2019-11-19T21:22:16+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Han Seokhyeon</title><subtitle>A blog about technology and stuff related</subtitle><entry><title type="html">docker pytorch image 이용해서 pytorch 사용하기</title><link href="http://localhost:4000/docker-pytorch/" rel="alternate" type="text/html" title="docker pytorch image 이용해서 pytorch 사용하기" /><published>2019-11-10T16:06:00+09:00</published><updated>2019-11-10T16:06:00+09:00</updated><id>http://localhost:4000/docker-pytorch</id><content type="html" xml:base="http://localhost:4000/docker-pytorch/">&lt;p&gt;이젠 더이상 피할 수 없다. 도커를 이용해 딥러닝해보자.&lt;/p&gt;

&lt;h1 id=&quot;1-nvidia-pytorch-image-pull&quot;&gt;1. Nvidia pytorch image pull&lt;/h1&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker pull nvcr.io/nvidia/pytorch:19.09-py3
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;와이파이로 해서 그런가 매우 오래걸렸다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker images
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;output:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;REPOSITORY               TAG                 IMAGE ID            CREATED             SIZE
nvcr.io/nvidia/pytorch   19.09-py3           9d6f9ccfbe31        2 months ago        9.15GB
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;9.15GB… 오래 걸린 이유가 있었다.&lt;/p&gt;

&lt;h1 id=&quot;2-run&quot;&gt;2. Run&lt;/h1&gt;

&lt;p&gt;돌려보자.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker run -i -t --name pytorch nvcr.io/nvidia/pytorch:19.09-py3 /bin/bash
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;터미널을 켜봤다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
=============
== PyTorch ==
=============

NVIDIA Release 19.09 (build 7911588)
PyTorch Version 1.2.0a0+afb7a16

Container image Copyright (c) 2019, NVIDIA CORPORATION.  All rights reserved.

Copyright (c) 2014-2019 Facebook Inc.
Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)
Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)
Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)
Copyright (c) 2011-2013 NYU                      (Clement Farabet)
Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)
Copyright (c) 2006      Idiap Research Institute (Samy Bengio)
Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)
Copyright (c) 2015      Google Inc.
Copyright (c) 2015      Yangqing Jia
Copyright (c) 2013-2016 The Caffe contributors
All rights reserved.

Various files include modifications (c) NVIDIA CORPORATION.  All rights reserved.
NVIDIA modifications are covered by the license terms that apply to the underlying project or file.

WARNING: The NVIDIA Driver was not detected.  GPU functionality will not be available.
   Use 'nvidia-docker run' to start this container; see
   https://github.com/NVIDIA/nvidia-docker/wiki/nvidia-docker .

NOTE: MOFED driver for multi-node communication was not detected.
      Multi-node communication performance may be reduced.

NOTE: The SHMEM allocation limit is set to the default of 64MB.  This may be
   insufficient for PyTorch.  NVIDIA recommends the use of the following flags:
   nvidia-docker run --ipc=host ...

root@14b57ccf6500:/workspace#
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;화려하다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;root@14b57ccf6500:/workspace# ls
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;output:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;README.md  docker-examples  examples  tutorials
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;정상적으로 실행하였다.&lt;/p&gt;

&lt;h1 id=&quot;3-host의-파이썬-프로젝트를-마운트&quot;&gt;3. Host의 파이썬 프로젝트를 마운트&lt;/h1&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker run -i -t --name pytorch -v /home/hanseokhyeon/PycharmProjects/speech_emotion_recognition:/workspace nvcr.io/nvidia/pytorch:19.09-py3 /bin/bash
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;따로 만들어둔 디렉토리가 없어서 그냥 workspace에 마운트하였다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ls
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;output:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;LICENSE    data_downloader.py  loader.py  models  result.py  save_model
README.md  dataset             main.py    result  run.sh     wavio.py
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;원래 있던 디렉토리와 파일들이 다 사라지고 내 파이썬 프로젝트로 대체되었다.&lt;/p&gt;

&lt;p&gt;돌려보자.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;python3 main.py
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;output:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[2019-11-10 07:01:46,762 pyplot.py:225 - switch_backend()] Loaded backend qt5agg version unknown.
[2019-11-10 07:01:46,796 pyplot.py:225 - switch_backend()] Loaded backend tkagg version unknown.
[2019-11-10 07:01:46,797 pyplot.py:225 - switch_backend()] Loaded backend agg version unknown.
[2019-11-10 07:01:46,797 pyplot.py:225 - switch_backend()] Loaded backend agg version unknown.
[2019-11-10 07:01:47,227 data_downloader.py:27 - data_download()] emo-db downloading
[2019-11-10 07:01:47,232 connectionpool.py:205 - _new_conn()] Starting new HTTP connection (1): emodb.bilderbar.info:80
[2019-11-10 07:01:49,233 connectionpool.py:393 - _make_request()] http://emodb.bilderbar.info:80 &quot;GET /download/download.zip HTTP/1.1&quot; 200 40567066
[2019-11-10 07:02:40,629 main.py:246 - main()] start
[2019-11-10 07:02:40,631 main.py:44 - train()] train() start
[2019-11-10 07:02:49,562 main.py:98 - train()] batch:    0/  46, loss: 1.9348, elapsed: 8.93s 0.15m 0.00h
Killed
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;돌아는 간다. 그런데 gpu 세팅을 안해줘서 그런지 pytorch가 cpu로 돌아간다. 무지막지한 네트워크를 그냥 노트북에서 돌리다보니 결국 8GB의 램은 견뎌주지 못했다.&lt;/p&gt;

&lt;p&gt;gpu로 도전해야겠다. 물론 서버에서.&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;출처:&lt;br /&gt;
&lt;a href=&quot;https://www.joinc.co.kr/w/man/12/docker/Guide/DataWithContainer&quot;&gt;https://www.joinc.co.kr/w/man/12/docker/Guide/DataWithContainer&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://brunch.co.kr/@hopeless/10&quot;&gt;https://brunch.co.kr/@hopeless/10&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://hanseokhyeon.github.io/docker-tutorial/&quot;&gt;https://hanseokhyeon.github.io/docker-tutorial/&lt;/a&gt;&lt;/p&gt;</content><author><name>HanSeokhyeon</name></author><category term="blog" /><summary type="html">이젠 더이상 피할 수 없다. 도커를 이용해 딥러닝해보자.</summary></entry><entry><title type="html">speech emotion recognition 연구 기록</title><link href="http://localhost:4000/speech-emotion-recognition/" rel="alternate" type="text/html" title="speech emotion recognition 연구 기록" /><published>2019-11-08T13:53:00+09:00</published><updated>2019-11-08T13:53:00+09:00</updated><id>http://localhost:4000/speech-emotion-recognition</id><content type="html" xml:base="http://localhost:4000/speech-emotion-recognition/">&lt;p&gt;맨날 공책에 연구기록 정리해놔도 다 없어진다. 그래서 이제 웹에 저장해볼까 한다.&lt;/p&gt;

&lt;h1 id=&quot;1-crnn-layer--2-2-3-filters--64-128-256&quot;&gt;1. CRNN, layer = [2, 2, 3], filters = [64, 128, 256]&lt;/h1&gt;
&lt;p&gt;epoch 19 loss 0.6085 acc 0.8649&lt;br /&gt;
epoch 41 loss 0.6767 acc 0.8198&lt;br /&gt;
epoch 15 loss 0.5758 acc 0.8378&lt;br /&gt;
epoch 37 loss 0.6570 acc 0.8108&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2019-11-08 13_50_33.png&quot; alt=&quot;2019-11-08-50-33&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;2-crnn-layer--2-3-3-filters--64-128-256&quot;&gt;2. CRNN, layer = [2, 3, 3], filters = [64, 128, 256]&lt;/h1&gt;
&lt;p&gt;epoch 10 loss 0.8609 acc 0.7297&lt;br /&gt;
epoch 7 loss 0.6213 acc 0.7838&lt;br /&gt;
epoch 41 loss 0.8283 acc 0.8378&lt;br /&gt;
epoch 35 loss 0.6847 acc 0.8468&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/2019-11-08 16:58:47.png&quot; alt=&quot;2019-11-08-16:58:47&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;3-crnn-layer--3-3-3-filters--64-128-256&quot;&gt;3. CRNN, layer = [3, 3, 3], filters = [64, 128, 256]&lt;/h1&gt;
&lt;p&gt;epoch 28 loss 0.6859 acc 0.8198&lt;br /&gt;
epoch 33 loss 0.7510 acc 0.8198&lt;br /&gt;
epoch 17 loss 0.7368 acc 0.8288 &lt;br /&gt;
epoch 17 loss 1.2993 acc 0.6757&lt;/p&gt;

&lt;h1 id=&quot;4-crnn-layer--2-2-2-filters--64-128-256&quot;&gt;4. CRNN, layer = [2, 2, 2], filters = [64, 128, 256]&lt;/h1&gt;
&lt;p&gt;epoch 16 loss 0.6999 acc 0.8108&lt;br /&gt;
epoch 18 loss 0.5953 acc 0.8198&lt;br /&gt;
epoch 8 loss 0.7030 acc 0.7568&lt;br /&gt;
epoch 11 loss 0.6641 acc 0.8288&lt;/p&gt;

&lt;h1 id=&quot;5-resnetrnn-layer--5-4-4-filters--64-128-256&quot;&gt;5. resnetRNN, layer = [5, 4, 4], filters = [64, 128, 256]&lt;/h1&gt;
&lt;p&gt;epoch 4 loss 0.7461 acc 0.7568&lt;br /&gt;
epoch 9 loss 0.9223 acc 0.6937&lt;/p&gt;

&lt;h1 id=&quot;6-resnetrnn-layer--3-2-2-filters--64-128-256&quot;&gt;6. resnetRNN, layer = [3, 2, 2], filters = [64, 128, 256]&lt;/h1&gt;
&lt;p&gt;epoch 4 loss 0.9112 acc 0.7027&lt;br /&gt;
epoch 7 loss 0.7967 acc 0.7117&lt;/p&gt;

&lt;h1 id=&quot;7-resnetrnn-layer--7-6-6-filters--64-128-256&quot;&gt;7. resnetRNN, layer = [7, 6, 6], filters = [64, 128, 256]&lt;/h1&gt;
&lt;p&gt;epoch 13 loss 1.5899 acc 0.6757&lt;br /&gt;
epoch 9 loss 0.9989 acc 0.7027&lt;/p&gt;

&lt;h1 id=&quot;8-resnetrnn-layer--9-8-8-filters--64-128-256&quot;&gt;8. resnetRNN, layer = [9, 8, 8], filters = [64, 128, 256]&lt;/h1&gt;
&lt;p&gt;epoch 18 loss 1.2800 acc 0.6667&lt;br /&gt;
epoch 4 loss 1.0925 acc 0.5856&lt;/p&gt;

&lt;h1 id=&quot;9-resnetrnn-layer--3-4-4-filters--64-128-256&quot;&gt;9. resnetRNN, layer = [3, 4, 4], filters = [64, 128, 256]&lt;/h1&gt;
&lt;p&gt;epoch 14 loss 0.9747 acc 0.6757&lt;br /&gt;
epoch 14 loss 0.8728 acc 0.7748&lt;br /&gt;
epoch 10 loss 0.8545 acc 0.7297&lt;br /&gt;
epoch 5 loss 0.8566 acc 0.6847&lt;/p&gt;

&lt;h1 id=&quot;10-resnetrnn-layer--3-4-4-filters--64-128-256-non_initialization&quot;&gt;10. resnetRNN, layer = [3, 4, 4], filters = [64, 128, 256], non_initialization&lt;/h1&gt;
&lt;p&gt;epoch 14 loss 0.8709 acc 0.7658&lt;br /&gt;
epoch 9 loss 0.9039 acc 0.7568&lt;/p&gt;

&lt;h1 id=&quot;11-resnetrnn-layer--5-4-4-filters--64-128-256-non_initialization&quot;&gt;11. resnetRNN, layer = [5, 4, 4], filters = [64, 128, 256], non_initialization&lt;/h1&gt;
&lt;p&gt;epoch 14 loss 0.9539 acc 0.7658&lt;br /&gt;
epoch 13 loss 0.9006 acc 0.7748&lt;/p&gt;

&lt;h1 id=&quot;12-resnetrnn-layer--7-6-6-filters--64-128-256-non_initialization&quot;&gt;12. resnetRNN, layer = [7, 6, 6], filters = [64, 128, 256], non_initialization&lt;/h1&gt;
&lt;p&gt;epoch 11 loss 1.2741 acc 0.5946&lt;br /&gt;
epoch 19 loss 1.5301 acc 0.6577&lt;/p&gt;

&lt;h1 id=&quot;13-resnetrnn-layer--3-2-2-filters--64-128-256-non_initialization&quot;&gt;13. resnetRNN, layer = [3, 2, 2], filters = [64, 128, 256], non_initialization&lt;/h1&gt;
&lt;p&gt;epoch 27 loss 1.6902 acc 0.6306&lt;br /&gt;
epoch 12 loss 1.6095 acc 0.6667&lt;/p&gt;

&lt;h1 id=&quot;14-crnn-layer--3-2-2-filters--64-128-256&quot;&gt;14. CRNN, layer = [3, 2, 2], filters = [64, 128, 256]&lt;/h1&gt;
&lt;p&gt;epoch 20 loss 1.1918 acc 0.7568
epoch 18 loss 1.2211 acc 0.7568&lt;/p&gt;

&lt;h1 id=&quot;15-crnn-layer--3-4-4-filters--64-128-256&quot;&gt;15. CRNN, layer = [3, 4, 4], filters = [64, 128, 256]&lt;/h1&gt;
&lt;p&gt;Epoch 16 (Test) Loss 0.9358 Acc 0.7477&lt;br /&gt;
Epoch 16 (Test) Loss 1.0985 Acc 0.7838
Epoch 28 (Test) Loss 1.1612 Acc 0.7477
Epoch 20 (Test) Loss 1.0648 Acc 0.7568&lt;/p&gt;</content><author><name>HanSeokhyeon</name></author><category term="blog" /><summary type="html">맨날 공책에 연구기록 정리해놔도 다 없어진다. 그래서 이제 웹에 저장해볼까 한다.</summary></entry><entry><title type="html">구글 colaboratory 시작하기!</title><link href="http://localhost:4000/google-colabotary/" rel="alternate" type="text/html" title="구글 colaboratory 시작하기!" /><published>2019-11-07T15:22:00+09:00</published><updated>2019-11-07T15:22:00+09:00</updated><id>http://localhost:4000/google-colabotary</id><content type="html" xml:base="http://localhost:4000/google-colabotary/">&lt;p&gt;다시 딥러닝 공부를 시작했고 데스크탑 하나로 실험하기 아쉬워서 구글 콜랩에 대해 공부를 시작하였다.&lt;/p&gt;

&lt;h1 id=&quot;1-데이터-올리기&quot;&gt;1. 데이터 올리기&lt;/h1&gt;

&lt;p&gt;구글 콜랩은 파일을 서버에 올릴 수 있지만 본인 아이디의 구글 드라이브와 연동하는 것이 가장 편리하다.&lt;/p&gt;

&lt;p&gt;구글 콜랩 첫 페이지는 이러하다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/colab_start.png&quot; alt=&quot;colab_start&quot; /&gt;&lt;/p&gt;

&lt;p&gt;오른쪽 위에 파일/새 Python3 노트를 눌러 새 노트를 열어보자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/colab_note.png&quot; alt=&quot;colab_note&quot; /&gt;&lt;/p&gt;

&lt;p&gt;구글 드라이브와 연동하기 위한 코드는 아래와 같다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from google.colab import drive
drive.mount('/gdrive', force_remount=True)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;코드를 실행하면 아래와 같이 머 링크 들어가서 로그인하고 인증코드를 입력하라고 한다. 방법은 어렵지 않으니 스크린샷은 생략한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/colab_googledrive.png&quot; alt=&quot;colab_googledrive&quot; /&gt;&lt;/p&gt;

&lt;p&gt;구글드라이브에 프로젝트를 올리기 전에 파일 형식이 구글 문서형식으로 자동으로 바뀌는 것을 방지하기 위해 구글드라이브에 가서 설정을 확인해본다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/colab_googledrive2.png&quot; alt=&quot;colab_googledrive2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;사진에 Convert uploads에 체크가 해제되어있으면 된다. 이후 자신이 올릴 프로그램을 구글 드라이브에 올린다. 방법은 어렵지 않으니 설명 생략…&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;!ls &quot;/gdrive/My Drive&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;콜랩에서 명령어를 사용하고 싶으면 !를 앞에 쓴 후 사용할 수 있다. 위와 같이 구글 드라이브 안에 내용이 궁금하면 볼 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/colab_ls.png&quot; alt=&quot;colab_ls&quot; /&gt;&lt;/p&gt;

&lt;p&gt;목록들이 잘 출력된다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;!python3 &quot;/gdrive/My Drive/speech_emotion_recognition/main.py&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;를 입력해 python 파일을 run해봤다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/colab_run.png&quot; alt=&quot;colab_run&quot; /&gt;&lt;/p&gt;

&lt;p&gt;돌아는 간다. 근데 매우 느리다. 생각해보니 GPU 설정을 안해줬다.&lt;/p&gt;

&lt;p&gt;/런타임/런타임 유형 변경에 들어가면 아래와 같이 GPU로 설정할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/colab_gpu.png&quot; alt=&quot;colab_gpu&quot; /&gt;&lt;/p&gt;

&lt;p&gt;바꾸고 나서 다시 돌려보았다. 뭐 빨라지긴했는데 그래도 로컬에서 돌릴때에 비해 좀 느리다… GTX 1070 &amp;gt; Tesla K80…? 여튼 공짜가 어디냐.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;출처:&lt;br /&gt;
&lt;a href=&quot;https://tykimos.github.io/2019/01/22/colab_getting_started/&quot;&gt;https://tykimos.github.io/2019/01/22/colab_getting_started/&lt;/a&gt;&lt;/p&gt;</content><author><name>HanSeokhyeon</name></author><category term="blog" /><summary type="html">다시 딥러닝 공부를 시작했고 데스크탑 하나로 실험하기 아쉬워서 구글 콜랩에 대해 공부를 시작하였다.</summary></entry><entry><title type="html">PyTorch contiguous() 함수</title><link href="http://localhost:4000/pytorch-contiguous/" rel="alternate" type="text/html" title="PyTorch contiguous() 함수" /><published>2019-11-01T18:40:00+09:00</published><updated>2019-11-01T18:40:00+09:00</updated><id>http://localhost:4000/pytorch-contiguous</id><content type="html" xml:base="http://localhost:4000/pytorch-contiguous/">&lt;p&gt;torch.contiguous()에 대해 알아보자.&lt;/p&gt;

&lt;h1 id=&quot;1-pytorch-documentation&quot;&gt;1. PyTorch documentation&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Returns a contiguous tensor containing the same data as self tensor. If self tensor is contiguous, this function returns the self tensor.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;라는데… 그러면 contiguous tensor가 먼데…?&lt;/p&gt;

&lt;p&gt;구글링을 시작했다.&lt;/p&gt;

&lt;h1 id=&quot;2-stack-overflow-글&quot;&gt;2. Stack overflow 글&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;There are few operations on Tensor in PyTorch that do not really change the content of the tensor, but only how to convert indices in to tensor to byte location. These operations include:&lt;br /&gt;
PyTorch의 텐서에는 텐서의 내용을 실제로 변경하지 않고, 인덱스만 바꿔 동작을 처리하는 함수들이 있습니다. 이러한 작업에는 다음이 포함됩니다.&lt;/p&gt;
  &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    narrow(), view(), expand() and transpose()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/div&gt;
  &lt;p&gt;For example: when you call &lt;code class=&quot;highlighter-rouge&quot;&gt;transpose()&lt;/code&gt;, PyTorch doesn’t generate new tensor with new layout, it just modifies meta information in Tensor object so offset and stride are for new shape. The transposed tensor and original tensor are indeed sharing the memory!&lt;br /&gt;
예를 들어, &lt;code class=&quot;highlighter-rouge&quot;&gt;transpose()&lt;/code&gt;를 호출하면 PyTorch는 새로운 레이아웃으로 새로운 텐서를 생성하지 않고, Tensor 객체에서 메타 정보를 수정하기 때문에 offset과 stride가 새로운 모양을 갖습니다. 바뀐 텐서와 원래 텐서는 실제로 메모리를 공유하고 있습니다!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;x = torch.randn(3,2)
y = torch.transpose(x, 0, 1)
x[0, 0] = 42
print(y[0,0])
# prints 42
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;This is where the concept of contiguous comes in. Above &lt;code class=&quot;highlighter-rouge&quot;&gt;x&lt;/code&gt; is contiguous but &lt;code class=&quot;highlighter-rouge&quot;&gt;y&lt;/code&gt; is not because its memory layout is different than a tensor of same shape made from scratch. Note that the word “contiguous” is bit misleading because its not that the content of tensor is spread out around disconnected blocks of memory. Here bytes are still allocated in one block of memory but the order of the elements is different!&lt;br /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;x&lt;/code&gt;는 연속적이지만 &lt;code class=&quot;highlighter-rouge&quot;&gt;y&lt;/code&gt;는 메모리 레이아웃이 처음부터 같은 모양의 텐서와 다르기 때문에 아닙니다. “연속적인”이라는 단어는 텐서의 내용이 연결이 끊어진 메모리 블록 주위에 퍼져 있지 않기 때문에 약간 오해의 소지가 있습니다. 여기서 바이트는 여전히 하나의 메모리 블록에 할당되지만 요소의 순서는 다릅니다!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;When you call &lt;code class=&quot;highlighter-rouge&quot;&gt;contiguous()&lt;/code&gt;, it actually makes a copy of tensor so the order of elements would be same as if tensor of same shape created from scratch.&lt;br /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;contiguous()&lt;/code&gt;를 호출하면 실제로 텐서의 복사본이 만들어 지므로 요소의 순서는 같은 모양의 텐서가 처음부터 만들어진 것처럼 같습니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Normally you don’t need to worry about this. If PyTorch expects contiguous tensor but if its not then you will get &lt;code class=&quot;highlighter-rouge&quot;&gt;RuntimeError: input is not contiguous&lt;/code&gt; and then you just add a call to &lt;code class=&quot;highlighter-rouge&quot;&gt;contiguous()&lt;/code&gt;.&lt;br /&gt;
일반적으로 당신은 이것에 대해 걱정할 필요가 없습니다. PyTorch가 연속적인 텐서를 기대하지만 그렇지 않은 경우 &lt;code class=&quot;highlighter-rouge&quot;&gt;RuntimeError : input is not contiguous&lt;/code&gt;가 아니라면 &lt;code class=&quot;highlighter-rouge&quot;&gt;contiguous()&lt;/code&gt;에 대한 호출을 추가합니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;친절한 개발자의 답변을 번역해보았다. 아마 메모리 아끼려고 pytorch가 이렇게 만들어지지 않았나싶다.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;출처:&lt;br /&gt;
&lt;a href=&quot;https://stackoverflow.com/questions/48915810/pytorch-contiguous&quot;&gt;https://stackoverflow.com/questions/48915810/pytorch-contiguous&lt;/a&gt;&lt;/p&gt;</content><author><name>HanSeokhyeon</name></author><category term="blog" /><summary type="html">torch.contiguous()에 대해 알아보자.</summary></entry><entry><title type="html">PyTorch nn.Sequential 알아보기</title><link href="http://localhost:4000/nn-sequential/" rel="alternate" type="text/html" title="PyTorch nn.Sequential 알아보기" /><published>2019-11-01T17:21:00+09:00</published><updated>2019-11-01T17:21:00+09:00</updated><id>http://localhost:4000/nn-sequential</id><content type="html" xml:base="http://localhost:4000/nn-sequential/">&lt;p&gt;PyTorch 코드를 구경하다보면 종종 nn.Sequential 함수가 보인다. 그래서 알아보았다.&lt;/p&gt;

&lt;h1 id=&quot;1-그냥-구현&quot;&gt;1. 그냥 구현&lt;/h1&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;class CNN(nn.Module):
    def __init__():
        super(CNN, self).__init__():

        self.conv1 = nn.Conv2d(1, 32, kernel_size=(41, 11), stride=(2, 2), padding=(20, 5))
        self.conv2 = nn.Conv2d(32, 32, kernel_size=(21, 11), stride=(2, 1), padding=(10, 5))
        self.bn = nn.BatchNorm2d(32)
        self.act = nn.Hardtanh(0, 20, inplace=True),
        
    def forward(self, x):
        x = self.conv1(x)
        x = self.bn(x)
        x = self.act(x)
        x = self.conv2(x)
        x = self.bn(x)
        x = self.act(x)
        return x
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;2-nnsequential-이용&quot;&gt;2. nn.Sequential 이용&lt;/h1&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;class CNN(nn.Module):
    def __init__():
        super(CNN, self).__init__():

        self.conv = nn.Sequential(
            nn.Conv2d(1, 32, kernel_size=(41, 11), stride=(2, 2), padding=(20, 5)),
            nn.BatchNorm2d(32),
            nn.Hardtanh(0, 20, inplace=True),
            nn.Conv2d(32, 32, kernel_size=(21, 11), stride=(2, 1), padding=(10, 5)),
            nn.BatchNorm2d(32),
            nn.Hardtanh(0, 20, inplace=True)
        )

    def forward(self, x):
        x = self.conv(x)
        return x
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;확실히 간결하게 사용할 수 있다.&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;출처:&lt;br /&gt;
&lt;a href=&quot;https://hichoe95.tistory.com/18&quot;&gt;https://hichoe95.tistory.com/18&lt;/a&gt;&lt;/p&gt;</content><author><name>HanSeokhyeon</name></author><category term="blog" /><summary type="html">PyTorch 코드를 구경하다보면 종종 nn.Sequential 함수가 보인다. 그래서 알아보았다.</summary></entry><entry><title type="html">파이썬의 *args와 **kwargs</title><link href="http://localhost:4000/args-kwargs/" rel="alternate" type="text/html" title="파이썬의 *args와 **kwargs" /><published>2019-11-01T16:47:00+09:00</published><updated>2019-11-01T16:47:00+09:00</updated><id>http://localhost:4000/args-kwargs</id><content type="html" xml:base="http://localhost:4000/args-kwargs/">&lt;p&gt;파이썬 코드를 보다보니 함수 인자에 *args와 **kwargs가 있는데 잘 몰라서 찾아보았다.&lt;/p&gt;

&lt;h1 id=&quot;1-args&quot;&gt;1. *args&lt;/h1&gt;

&lt;p&gt;*args는 함수의 인자로 들어온 내용이 list에 담긴다고 생각하면 된다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def myFun(*args):
    for arg in args:
        print(arg)

myFun('Hello', 'Welcome', 'to', 'HanSeokhyeon')
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;output:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Hello
Welcome
to
HanSeokhyeon
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;남은 인자를 싹 담는다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def myFun(arg1, *args):
    print(&quot;First: {}&quot;.format(arg1))
    for arg in args:
        print(&quot;Next: {}&quot;.format(arg))

myFun('Hello', 'Welcome', 'to', 'HanSeokhyeon')
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;output:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;First: Hello
Next: Welcome
Next: to
Next: HanSeokhyeon
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;2-kwargs&quot;&gt;2. **kwargs&lt;/h1&gt;

&lt;p&gt;**kwargs는 함수의 인자로 들어온 내용이 dictionary에 담긴다고 생각하면 된다. Dictionary에 담기 위해 key를 지정해줘야한다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def myFun(**kwargs):  
    for key, value in kwargs.items(): 
        print (&quot;%s == %s&quot; %(key, value)) 
  
myFun(first ='Han', mid ='seok', last='hyeon')
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;output:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;first == Han
mid == seok
last == hyeon
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;마찬가지로 가능하다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def myFun(arg1, **kwargs):
    print(&quot;First: {}&quot;.format(arg1))
    for key, value in kwargs.items(): 
        print (&quot;%s == %s&quot; %(key, value)) 
  
myFun('Hi', first ='Han', mid ='seok', last='hyeon')
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;output:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;First: Hi
first == Han
mid == seok
last == hyeon
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;3-args와-kwargs-둘-다-사용하기&quot;&gt;3. *args와 **kwargs 둘 다 사용하기&lt;/h1&gt;

&lt;p&gt;같이 쓰면 key가 없으면 args로, key가 있으면 kwargs로 들어간다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def myFun(*args, **kwargs):
    for arg in args:
        print(&quot;args: {}&quot;.format(arg))
    for key, value in kwargs.items(): 
        print (&quot;%s == %s&quot; %(key, value)) 
  
myFun('Hi', 'everyone', first ='Han', mid ='seok', last='hyeon')
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;output:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;argv: Hi
argv: everyone
first == Han
mid == seok
last == hyeon
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;
&lt;p&gt;출처:&lt;br /&gt;
&lt;a href=&quot;https://www.geeksforgeeks.org/args-kwargs-python/&quot;&gt;https://www.geeksforgeeks.org/args-kwargs-python/&lt;/a&gt;&lt;/p&gt;</content><author><name>HanSeokhyeon</name></author><category term="blog" /><summary type="html">파이썬 코드를 보다보니 함수 인자에 *args와 **kwargs가 있는데 잘 몰라서 찾아보았다.</summary></entry><entry><title type="html">Apache license 2.0에 대해 알아보자.</title><link href="http://localhost:4000/apache-license-2/" rel="alternate" type="text/html" title="Apache license 2.0에 대해 알아보자." /><published>2019-11-01T16:28:00+09:00</published><updated>2019-11-01T16:28:00+09:00</updated><id>http://localhost:4000/apache-license-2</id><content type="html" xml:base="http://localhost:4000/apache-license-2/">&lt;p&gt;CRNN을 이용한 speech emotion recognition 코드를 작성하고 있는데 github에 업로드할 예정이다. Naver의 Speech AI hackathon 코드를 참고 중인데 코드에 적용된 license가 Apache license 2.0이어서 공부하였다.&lt;/p&gt;

&lt;h1 id=&quot;1-요약&quot;&gt;1. 요약&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Apache license는 원 저작물을 어떠한 방식으로 사용하든지 상관이 없다.&lt;/li&gt;
  &lt;li&gt;2차 저작물은 소스 코드를 공개할 의무가 없으며, Apache license를 사용하지 않아도 된다.&lt;/li&gt;
  &lt;li&gt;사용 결과에 대해서 원 저작자가 책임을 지지 않는다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;2-사용법&quot;&gt;2. 사용법&lt;/h1&gt;

&lt;h2 id=&quot;1-code에-저작권-명시&quot;&gt;1. code에 저작권 명시&lt;/h2&gt;

&lt;p&gt;아래에 원 저작자를 코드 맨 처음에 명시하면 된다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&quot;&quot;&quot;

Copyright 2017- IBM Corporation

Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

&quot;&quot;&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;2-project에-license-포함&quot;&gt;2. project에 license 포함&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/moby/moby/blob/master/LICENSE&quot;&gt;여기&lt;/a&gt;에 가보면 Apache license 2.0 원본이 있다. 이 원본을 개인 프로젝트에 포함하면 된다.&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;출처:&lt;br /&gt;
&lt;a href=&quot;https://linuxism.ustd.ip.or.kr/1143&quot;&gt;https://linuxism.ustd.ip.or.kr/1143&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://jm4488.tistory.com/4&quot;&gt;https://jm4488.tistory.com/4&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://www.oss.kr/oss_license_qna/show/8c7cf208-7c24-499f-b143-9c0f7b22ab6a&quot;&gt;https://www.oss.kr/oss_license_qna/show/8c7cf208-7c24-499f-b143-9c0f7b22ab6a&lt;/a&gt;&lt;/p&gt;</content><author><name>HanSeokhyeon</name></author><category term="blog" /><summary type="html">CRNN을 이용한 speech emotion recognition 코드를 작성하고 있는데 github에 업로드할 예정이다. Naver의 Speech AI hackathon 코드를 참고 중인데 코드에 적용된 license가 Apache license 2.0이어서 공부하였다.</summary></entry><entry><title type="html">Pycharm SSH로 서버에서 run하기</title><link href="http://localhost:4000/pycharm-ssh-run/" rel="alternate" type="text/html" title="Pycharm SSH로 서버에서 run하기" /><published>2019-11-01T13:44:00+09:00</published><updated>2019-11-01T13:44:00+09:00</updated><id>http://localhost:4000/pycharm-ssh-run</id><content type="html" xml:base="http://localhost:4000/pycharm-ssh-run/">&lt;p&gt;지난 포스트에서 파이참에서 서버의 터미널을 여는 것 까지 성공했다. 하지만 진짜 파이참으로 이용해 딥러닝 개발을 하기 위해서는 run까지 해야한다. 그래서 공부해봤다.&lt;/p&gt;

&lt;h1 id=&quot;1-interpreter-설정&quot;&gt;1. Interpreter 설정&lt;/h1&gt;

&lt;p&gt;Files/Settings에 들어간다. 다시 Project: ***/Project Interpreter를 누르면 아래와 같은 화면을 볼 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/project_interpreter.png&quot; alt=&quot;project_interpreter&quot; /&gt;&lt;/p&gt;

&lt;p&gt;오른쪽 위에 톱니바퀴모양 설정 버튼을 누르고 추가적으로 add까지 누른다. 다시 SSH Interpreter를 누르면 아래와 같은 화면을 볼 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ssh_interpreter.png&quot; alt=&quot;ssh_interpreter&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Host에는 서버의 IP주소, Username은 서버의 name을 입력한다. Port 번호를 변경했다면 바꾼 번호로 입력한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ssh_interpreter2.png&quot; alt=&quot;ssh_interpreter2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Password를 사용한다면 password를, 공개키를 사용한다면 공개키 정보를 입력한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ssh_interpreter3.png&quot; alt=&quot;ssh_interpreter3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;흠 머 finish.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ssh_interpreter4.png&quot; alt=&quot;ssh_interpreter4&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이렇게 이제 새로운 ssh interpreter가 생겼다. 서버에 깔려있는 파이썬 패키지들이 눈에 들어온다.&lt;/p&gt;

&lt;p&gt;OK를 누르면 로컬에 있는 파이썬 프로젝트가 서버에 /tmp/pycharm_project로 전송된다. 전송이 완료되고 나서 평소 파이썬 코드를 돌리듯이 run하면 서버에서 코드가 돌아간다. 신난다!&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;출처:&lt;br /&gt;
&lt;a href=&quot;https://simonjisu.github.io/datascience/2018/06/24/pycharmssh.html&quot;&gt;https://simonjisu.github.io/datascience/2018/06/24/pycharmssh.html&lt;/a&gt;&lt;/p&gt;</content><author><name>HanSeokhyeon</name></author><category term="blog" /><summary type="html">지난 포스트에서 파이참에서 서버의 터미널을 여는 것 까지 성공했다. 하지만 진짜 파이참으로 이용해 딥러닝 개발을 하기 위해서는 run까지 해야한다. 그래서 공부해봤다.</summary></entry><entry><title type="html">Pycharm SSH Terminal 연결하기</title><link href="http://localhost:4000/pycharm-ssh-terminal/" rel="alternate" type="text/html" title="Pycharm SSH Terminal 연결하기" /><published>2019-11-01T11:31:00+09:00</published><updated>2019-11-01T11:31:00+09:00</updated><id>http://localhost:4000/pycharm-ssh-terminal</id><content type="html" xml:base="http://localhost:4000/pycharm-ssh-terminal/">&lt;p&gt;연구실의 데스크탑을 서버로 사용하고 개인 노트북을 로컬로 사용하려고 시도하고 있다. SSH server로 데스크탑 우분투로 접속하는 것을 성공했지만, 좀 더 편한 이용을 위해 PyCharm Professional에서 지원하는 SSH plugin을 사용해보고자 한다. 참고로 PyCharm Professional은 유료버전이나 학생인증을 하면 무료로 사용할 수 있다.&lt;/p&gt;

&lt;h1 id=&quot;1-ssh-server-접속-환경-구축&quot;&gt;1. SSH server 접속 환경 구축&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;https://hanseokhyeon.github.io/ssh-server/&quot;&gt;여기&lt;/a&gt;를 참고하길 바란다.&lt;/p&gt;

&lt;h1 id=&quot;2-pycharm-ssh-remote-run-plugin-설치&quot;&gt;2. Pycharm SSH Remote Run plugin 설치&lt;/h1&gt;

&lt;p&gt;SSH Remote Run은 bundle plugin이므로 기본적으로 설치 되어 있을 것이다.&lt;/p&gt;

&lt;p&gt;Settings/Plugins에 installed를 눌러서 설치가 되어 있는지 확인하자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ssh_remote_run.png&quot; alt=&quot;ssh_remote_run&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;3-ssh-terminal-연결&quot;&gt;3. SSH terminal 연결&lt;/h1&gt;

&lt;p&gt;메인메뉴에 Tools/Start SSH Session을 누르면 정보를 입력하는 창이 뜬다. 평소에 터미널로 SSH server에 접속하듯이 호스트, 사용자, 포트번호, 비밀번호를 입력하면 터미널이 연결된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ssh_session.png&quot; alt=&quot;ssh_session&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이와 같이 입력하면&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/terminal.png&quot; alt=&quot;terminal&quot; /&gt;&lt;/p&gt;

&lt;p&gt;연결된다. 다음에는 run을 서버에서 하는 방법을 연구할 계획이다.&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;출처:&lt;br /&gt;
&lt;a href=&quot;https://www.jetbrains.com/help/pycharm/running-ssh-terminal.html&quot;&gt;https://www.jetbrains.com/help/pycharm/running-ssh-terminal.html&lt;/a&gt;&lt;/p&gt;</content><author><name>HanSeokhyeon</name></author><category term="blog" /><summary type="html">연구실의 데스크탑을 서버로 사용하고 개인 노트북을 로컬로 사용하려고 시도하고 있다. SSH server로 데스크탑 우분투로 접속하는 것을 성공했지만, 좀 더 편한 이용을 위해 PyCharm Professional에서 지원하는 SSH plugin을 사용해보고자 한다. 참고로 PyCharm Professional은 유료버전이나 학생인증을 하면 무료로 사용할 수 있다.</summary></entry><entry><title type="html">gdb에서 fopen 함수 디버깅시 step을 사용했을 때 에러</title><link href="http://localhost:4000/gdb-step-error/" rel="alternate" type="text/html" title="gdb에서 fopen 함수 디버깅시 step을 사용했을 때 에러" /><published>2019-10-31T12:50:00+09:00</published><updated>2019-10-31T12:50:00+09:00</updated><id>http://localhost:4000/gdb-step-error</id><content type="html" xml:base="http://localhost:4000/gdb-step-error/">&lt;p&gt;gdb를 이용해 step 명령어를 사용해 디버깅시 fopen에서 파일을 찾을 수 없다며 에러가 나는 것을 확인하였다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Breakpoint 1, main () at main.c:24
24			file_sp.err_sp = fopen(&quot;out/han/SP/error.csv&quot;, &quot;wt&quot;); // save error of estimating secondary path 
(gdb) s
_IO_new_fopen (filename=0x555555556383 &quot;out/han/SP/error.csv&quot;, mode=0x555555556380 &quot;wt&quot;) at iofopen.c:88
88	iofopen.c: 그런 파일이나 디렉터리가 없습니다.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;찾아보니 step과 next 명령어의 차이점에서 나타나는 문제였는데 영어로는 설명이 이렇다.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;“The step command follows the code into a function call. When stepping, gdb prints each source line before executing it. If you step into a library function, gdb wants to display the source, but those file are not available on the system. The complaint is expected and harmless. If you use the next command instead, it will step over and treat the entire call as a single step.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;“step 명령어는 코드를 따라 함수 호출로 이어집니다. step 할 때 gdb는 각 소스 라인을 실행하기 전에 인쇄합니다. 라이브러리 함수로 들어가면 gdb가 소스를 표시하려고하지만 해당 파일을 시스템에서 사용할 수 없습니다. 다음 명령을 대신 사용하면 전체 호출이 한 단계 씩 처리됩니다.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;머 이렇단다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Breakpoint 1, main () at main.c:24
24			file_sp.err_sp = fopen(&quot;out/han/SP/error.csv&quot;, &quot;wt&quot;); // save error of estimating secondary path 
(gdb) n
25			file_sp.f_white = fopen(&quot;data/han/SP/white_noise_11second_16k.raw&quot;, &quot;rb&quot;); // original
(gdb) 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;s 대신 n을 사용하니 정상적으로 작동한다.&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;출처:&lt;br /&gt;
&lt;a href=&quot;https://stackoverflow.com/questions/25564864/trouble-with-opening-file-for-read-with-fopen/25564973&quot;&gt;https://stackoverflow.com/questions/25564864/trouble-with-opening-file-for-read-with-fopen/25564973&lt;/a&gt;&lt;/p&gt;</content><author><name>HanSeokhyeon</name></author><category term="blog" /><summary type="html">gdb를 이용해 step 명령어를 사용해 디버깅시 fopen에서 파일을 찾을 수 없다며 에러가 나는 것을 확인하였다.</summary></entry></feed>